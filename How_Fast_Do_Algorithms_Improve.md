《》
## 《How Fast Do Algorithms Improve》阅读报告
### 文献链接：[https://ide.mit.edu/wp-content/uploads/2021/09/How_Fast_Do_Algorithms_Improve.pdf](https://ide.mit.edu/wp-content/uploads/2021/09/How_Fast_Do_Algorithms_Improve.pdf)
### 主要内容：
##### 当前算法研究的现状

文章指出，当前对算法发展进程的研究极其有限。算法改进是否足够快？改进的平均效果如何？等等。这些都没有明确的结论。

研究团队发现超过一半的算法族只有很少或没有改进。而在另一个极端，14%的算法族有变革性的改进。总体来说，对于中等规模的问题，30%~43%的算法族的改进已经相当于甚至大于用户从摩尔定律和其他硬件方面感受到的改进。

本文提供了有史以来第一次全面的分析算法发展的进展，这使得我们能够系统的研究何时发现算法，它们是如何改进的，以及这些改进的规模与其他创新来源相比如何。文章首次提供了系统、定了的证据，证明算法是计算改进的最重要来源之一。

##### 研究手段
一些定义：
* 算法族：解决同一类问题的算法集合，如归并排序和起泡排序被归为“比较排序”算法族。研究团队划分了113个算法族，平均每个族有8个算法。如果一个算法族里面某个算法的最坏渐进时间复杂度的降低了，就认为这个算法（族）有改进


* 算法改进率：
$$
\text { Improvement }_{i \rightarrow j}=\frac{\text { Operations }_{i}(n)}{\text { Operations }_{j}(n)}
$$

* 年平均改进率：
$$\text{ YearlyImprovement }_{i \rightarrow j} =\left(\frac{\text { Operations }_{i}(n)}{\text { Operations }_{j}(n)}\right)^{1 / t}-1
$$

注：t为从1940年算起的所经过的年份

* 复杂度由一个类别转移到另一个类别的概率：
$$
\begin{array}{l}
\operatorname{prob}(a \rightarrow b) =\frac{1}{T} \sum_{t \in T} \frac{\|a \rightarrow b\|_{t}}{\|a\|_{t-1}+\sum_{r \in C}\|c \rightarrow a\| l_{t}}
\end{array}
$$

注：t为所经过的年份


研究人员从20个顶级的计算机科学课程中，列出了11个算法子领域，分析了一个57本教科书，然后从中列出一个算法列表，最后把它们归入特定的算法族当中。他们还搜索了学术期刊、在线课程材料、维基百科和已经发表的论文，为教科书中确定算法族寻找其他算法改进。

##### 研究结果

1. 算法改进的趋势

调查发现，有276个算法有改进，平均每个算法族有1.44个改进的算法。在1970年代，大约34%的算法族已经被改进。之后的几十年，算法发现和改进的频率呈下降趋势：【图一】
一种可能性是，某些算法在理论上已经处于最佳状态，因此很难再取得改进。另一种可能性是，算法创新的回报正在减少

下图表明【图二】
还有31%的算法族其时间复杂度仍处于指数复杂度水平（$n ! | c^{n}$），另外50%的是属于多项式时间复杂度，还有19%的是$n \log n$ 或更好

由算法年平均转移概率可见，具有指数时间复杂度的算法转移为多项式时间复杂度的算法，这些改进可产生深远的影响，使得以前对于大型数据集不可行的算法，现在成为可行的算法：【图三】

2. 算法改进带来的影响

随着算法的改进，相同时间内能够处理的数据量也大为提升。下图列出的4个算法族，它们随着年份增长，获得了改进，处理的数据量呈直线式的上升：【图四】

图中还标有根据摩尔定律，硬件随年份的改进趋势，对比算法的改进，硬件的改进对处理数据量的提升显得相当平滑。

下面一张图将算法族分为两大类：【图五】
超过一半是比硬件“慢”的算法族。它们可能是一些人们比较少关注的算法，或者是已经在数学上达到最优的算法。
另一半算法族是比硬件“快”的，其中14%的年平均改进率还达到1000%。
三个子图分别对应于不同的数据量。随着数据量的增大，年平均改进的算法族数量的中位数也随之提高。

由此可得：（1）算法改进带来的改变问题的可操作性，是硬件改进不能比拟的；（2）随着数据量的大量提升，算法的改进比硬件的改进显得更加重要。这些发现表面算法的改进在比如数据分析和机器学习领域上相当重要，因为它们都依赖于大数据。


3.算法步分析

在算法分析的时候，常常会忽略一些关键常量，如时间复杂度$0.5(n^2+n)$会简化为$n^2$。如果算法的改进会伴随着关键常量的浮动变化，那这些关键常量可能是不能忽略的。如果关键常量的浮动明显，那表明我们的研究结果可能高估了算法改进的规模。反之，如果关键常量平均来看不增不减，那么忽略它们是安全的。
下图可见【图六】
算法步数的改进与算法性能的改进是几乎相当的，因此对于大多数算法，实际没有系统性的影响关键常量的浮动。